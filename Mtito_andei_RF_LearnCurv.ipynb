{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90958cd4-f4a3-47b2-bc32-3b30009baa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rasters...\n",
      "Loaded LD.tif: (1024, 1280), uint8\n",
      "Loaded D2F.tif: (1024, 1280), uint8\n",
      "Loaded Map.tif: (1024, 1280), uint8\n",
      "Extracting patches efficiently...\n",
      "\n",
      "Class distribution:\n",
      "138    697044\n",
      "224    580040\n",
      "226     15099\n",
      "225      5042\n",
      "227      2219\n",
      "        ...  \n",
      "71          3\n",
      "243         2\n",
      "170         2\n",
      "254         1\n",
      "249         1\n",
      "Name: count, Length: 202, dtype: int64\n",
      "\n",
      "Training memory-efficient Random Forest...\n",
      "Model saved to E:/mtito_andei/outputs\\memory_efficient_rf_model.joblib\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gojef\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gojef\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gojef\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Class 138       0.99      1.00      0.99       154\n",
      "   Class 224       0.62      0.62      0.62         8\n",
      "   Class 226       0.69      0.73      0.71        15\n",
      "   Class 225       1.00      0.50      0.67         4\n",
      "   Class 227       0.00      0.00      0.00         2\n",
      "    Class 50       0.50      0.25      0.33         4\n",
      "   Class 228       0.80      0.92      0.86        13\n",
      "   Class 232       1.00      1.00      1.00         3\n",
      "   Class 223       1.00      1.00      1.00         2\n",
      "   Class 240       0.00      0.00      0.00         2\n",
      "   Class 167       0.50      0.20      0.29         5\n",
      "   Class 101       0.67      0.67      0.67         3\n",
      "   Class 197       0.75      1.00      0.86         3\n",
      "   Class 204       0.50      0.75      0.60         4\n",
      "   Class 178       0.67      1.00      0.80         4\n",
      "   Class 229       1.00      0.75      0.86         4\n",
      "    Class 52       1.00      1.00      1.00         2\n",
      "   Class 217       1.00      0.67      0.80         3\n",
      "   Class 155       0.60      0.43      0.50         7\n",
      "   Class 104       1.00      0.50      0.67         2\n",
      "   Class 107       1.00      0.50      0.67         2\n",
      "    Class 56       0.60      0.60      0.60         5\n",
      "   Class 126       0.50      0.50      0.50         4\n",
      "    Class 85       0.33      0.50      0.40         2\n",
      "   Class 183       0.80      1.00      0.89         4\n",
      "   Class 192       0.50      0.50      0.50         4\n",
      "   Class 255       1.00      0.83      0.91         6\n",
      "   Class 216       1.00      0.67      0.80         3\n",
      "   Class 139       1.00      1.00      1.00         2\n",
      "   Class 174       0.00      0.00      0.00         1\n",
      "   Class 198       0.33      0.50      0.40         2\n",
      "   Class 171       0.00      0.00      0.00         2\n",
      "   Class 159       1.00      0.33      0.50         3\n",
      "   Class 195       0.71      1.00      0.83        12\n",
      "   Class 222       1.00      1.00      1.00         4\n",
      "   Class 156       0.50      1.00      0.67         1\n",
      "   Class 163       0.43      0.50      0.46         6\n",
      "   Class 218       1.00      0.60      0.75         5\n",
      "    Class 51       1.00      0.50      0.67         2\n",
      "   Class 187       0.00      0.00      0.00         2\n",
      "   Class 241       0.00      0.00      0.00         1\n",
      "    Class 68       0.00      0.00      0.00         1\n",
      "   Class 209       0.57      0.67      0.62         6\n",
      "   Class 109       0.00      0.00      0.00         2\n",
      "    Class 88       0.00      0.00      0.00         1\n",
      "   Class 165       0.80      0.80      0.80         5\n",
      "   Class 248       0.50      0.50      0.50         2\n",
      "    Class 77       0.67      1.00      0.80         2\n",
      "   Class 149       1.00      0.33      0.50         3\n",
      "   Class 194       0.88      0.95      0.91        39\n",
      "   Class 219       0.50      1.00      0.67         2\n",
      "   Class 191       0.00      0.00      0.00         1\n",
      "    Class 94       0.88      1.00      0.93        14\n",
      "   Class 247       0.67      0.50      0.57         4\n",
      "   Class 193       0.00      0.00      0.00         1\n",
      "   Class 164       0.93      1.00      0.96        13\n",
      "    Class 60       0.50      0.50      0.50         4\n",
      "   Class 112       0.56      0.71      0.62         7\n",
      "    Class 89       0.50      0.50      0.50         2\n",
      "   Class 230       1.00      0.67      0.80         3\n",
      "   Class 130       0.67      0.80      0.73         5\n",
      "   Class 142       0.00      0.00      0.00         2\n",
      "   Class 166       1.00      0.25      0.40         4\n",
      "   Class 206       0.00      0.00      0.00         2\n",
      "    Class 97       0.67      1.00      0.80         4\n",
      "   Class 151       0.00      0.00      0.00         4\n",
      "   Class 238       1.00      1.00      1.00         2\n",
      "   Class 184       0.00      0.00      0.00         3\n",
      "   Class 190       0.00      0.00      0.00         1\n",
      "   Class 146       1.00      0.67      0.80         3\n",
      "   Class 162       0.00      0.00      0.00         1\n",
      "   Class 182       1.00      0.50      0.67         2\n",
      "    Class 72       0.00      0.00      0.00         1\n",
      "   Class 108       0.47      0.67      0.55        12\n",
      "    Class 73       0.50      1.00      0.67         1\n",
      "   Class 186       0.00      0.00      0.00         1\n",
      "   Class 133       0.00      0.00      0.00         2\n",
      "    Class 53       0.67      0.40      0.50         5\n",
      "    Class 76       0.50      0.33      0.40         3\n",
      "   Class 221       0.00      0.00      0.00         2\n",
      "    Class 75       0.25      0.50      0.33         4\n",
      "   Class 157       0.00      0.00      0.00         3\n",
      "   Class 117       1.00      0.25      0.40         4\n",
      "   Class 210       0.67      0.67      0.67         3\n",
      "    Class 65       0.00      0.00      0.00         4\n",
      "   Class 215       0.60      0.88      0.71    139409\n",
      "   Class 208       0.64      0.82      0.72        11\n",
      "   Class 177       0.00      0.00      0.00         2\n",
      "   Class 201       0.00      0.00      0.00         1\n",
      "   Class 202       0.67      0.40      0.50         5\n",
      "   Class 211       0.50      0.67      0.57         3\n",
      "   Class 196       0.00      0.00      0.00         2\n",
      "   Class 135       1.00      0.50      0.67         2\n",
      "   Class 105       0.50      0.20      0.29         5\n",
      "   Class 114       0.00      0.00      0.00         3\n",
      "   Class 231       0.50      0.33      0.40         3\n",
      "    Class 64       0.71      0.83      0.77         6\n",
      "   Class 214       0.50      0.33      0.40         3\n",
      "    Class 86       0.25      0.20      0.22         5\n",
      "   Class 118       0.00      0.00      0.00         2\n",
      "    Class 55       0.00      0.00      0.00         1\n",
      "   Class 205       0.00      0.00      0.00         3\n",
      "   Class 137       0.76      0.87      0.81        15\n",
      "    Class 63       0.00      0.00      0.00         9\n",
      "   Class 122       0.20      0.25      0.22         4\n",
      "   Class 168       0.00      0.00      0.00         2\n",
      "   Class 189       0.67      0.40      0.50        10\n",
      "   Class 147       0.00      0.00      0.00         2\n",
      "   Class 134       0.00      0.00      0.00         3\n",
      "    Class 84       0.60      0.60      0.60         5\n",
      "   Class 143       0.57      0.44      0.50         9\n",
      "   Class 220       0.40      0.40      0.40         5\n",
      "   Class 150       0.40      0.33      0.36         6\n",
      "   Class 185       0.33      0.20      0.25         5\n",
      "   Class 154       0.43      0.36      0.39        42\n",
      "   Class 161       0.00      0.00      0.00         3\n",
      "    Class 61       0.00      0.00      0.00         2\n",
      "   Class 100       0.36      0.40      0.38        10\n",
      "    Class 57       0.00      0.00      0.00         2\n",
      "   Class 239       0.00      0.00      0.00         1\n",
      "    Class 62       0.67      0.55      0.60        11\n",
      "   Class 136       0.00      0.00      0.00         2\n",
      "   Class 111       1.00      0.50      0.67         2\n",
      "   Class 120       0.40      0.50      0.44         4\n",
      "    Class 67       0.60      0.86      0.71        21\n",
      "   Class 181       1.00      0.50      0.67         2\n",
      "   Class 207       0.00      0.00      0.00         1\n",
      "   Class 236       0.33      0.33      0.33         3\n",
      "   Class 188       0.60      0.60      0.60         5\n",
      "   Class 234       0.50      0.17      0.25        12\n",
      "   Class 148       0.50      0.20      0.29         5\n",
      "    Class 78       0.00      0.00      0.00         3\n",
      "   Class 131       0.00      0.00      0.00         4\n",
      "   Class 119       0.45      0.62      0.53         8\n",
      "   Class 179       1.00      0.33      0.50         3\n",
      "   Class 200       0.00      0.00      0.00         3\n",
      "   Class 132       1.00      0.20      0.33         5\n",
      "   Class 199       0.50      0.50      0.50         6\n",
      "    Class 91       1.00      0.17      0.29        12\n",
      "    Class 99       0.50      0.20      0.29         5\n",
      "    Class 74       0.57      0.67      0.62         6\n",
      "    Class 59       0.31      0.40      0.35        10\n",
      "   Class 113       0.40      0.50      0.44         4\n",
      "   Class 160       0.40      0.32      0.36        25\n",
      "   Class 129       0.00      0.00      0.00        11\n",
      "   Class 110       0.00      0.00      0.00         2\n",
      "    Class 98       0.40      1.00      0.57         2\n",
      "    Class 54       0.50      0.75      0.60         4\n",
      "    Class 95       1.00      0.25      0.40         4\n",
      "   Class 145       0.00      0.00      0.00         2\n",
      "   Class 212       0.75      0.82      0.78        22\n",
      "   Class 233       0.17      0.25      0.20         4\n",
      "    Class 70       0.20      0.20      0.20         5\n",
      "   Class 140       0.00      0.00      0.00         3\n",
      "   Class 152       1.00      0.50      0.67         4\n",
      "    Class 82       0.00      0.00      0.00         7\n",
      "   Class 169       0.40      0.50      0.44         4\n",
      "   Class 102       0.25      0.25      0.25         4\n",
      "    Class 90       0.00      0.00      0.00         2\n",
      "    Class 58       0.00      0.00      0.00         2\n",
      "   Class 176       0.33      0.25      0.29         4\n",
      "   Class 203       0.00      0.00      0.00         4\n",
      "   Class 213       0.78      0.64      0.70        11\n",
      "   Class 172       0.57      0.80      0.67        15\n",
      "    Class 81       0.62      0.62      0.62         8\n",
      "   Class 175       0.00      0.00      0.00         6\n",
      "   Class 115       1.00      0.33      0.50         3\n",
      "   Class 158       0.00      0.00      0.00         4\n",
      "   Class 144       0.00      0.00      0.00        10\n",
      "    Class 66       0.80      0.09      0.16        45\n",
      "    Class 79       0.62      0.29      0.40    116008\n",
      "    Class 69       0.55      0.06      0.11      1009\n",
      "   Class 124       0.58      0.02      0.03      3020\n",
      "   Class 235       0.29      0.00      0.01       444\n",
      "    Class 80       0.00      0.00      0.00        95\n",
      "    Class 87       0.50      0.07      0.12        15\n",
      "   Class 153       0.00      0.00      0.00         5\n",
      "    Class 92       1.00      0.25      0.40         4\n",
      "   Class 103       0.49      0.65      0.56        62\n",
      "   Class 180       0.00      0.00      0.00         2\n",
      "   Class 237       0.00      0.00      0.00         3\n",
      "   Class 245       0.00      0.00      0.00         1\n",
      "   Class 173       1.00      0.33      0.50         3\n",
      "   Class 123       0.00      0.00      0.00         1\n",
      "   Class 128       0.00      0.00      0.00         5\n",
      "   Class 141       0.00      0.00      0.00         3\n",
      "   Class 106       0.58      0.68      0.62        44\n",
      "   Class 127       0.00      0.00      0.00         7\n",
      "   Class 125       0.00      0.00      0.00         1\n",
      "   Class 121       0.43      0.50      0.46         6\n",
      "    Class 93       0.00      0.00      0.00         6\n",
      "    Class 96       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.60    261218\n",
      "   macro avg       0.43      0.37      0.37    261218\n",
      "weighted avg       0.61      0.60      0.56    261218\n",
      "\n",
      "Accuracy: 0.6040\n",
      "\n",
      "Generating full prediction map (chunked processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Process Complete ===\n",
      "✅ All outputs saved to: E:/mtito_andei/outputs\n",
      "\n",
      "Generating learning curve...\n",
      "Learning curve saved.\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.util import view_as_windows\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import median_filter\n",
    "import joblib\n",
    "\n",
    "# === Configuration ===\n",
    "PATCH_SIZE = 3\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "MIN_SAMPLES_PER_CLASS = 5  # Balanced between accuracy and memory\n",
    "OUTPUT_DIR = \"E:/mtito_andei/outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Memory-optimized Random Forest parameters\n",
    "RF_PARAMS = {\n",
    "    'n_estimators': 50,      # Reduced from 100 to save memory\n",
    "    'max_depth': 15,         # Limited depth to prevent overfitting\n",
    "    'min_samples_split': 5,  # Increased to reduce tree complexity\n",
    "    'max_features': 'sqrt',  # Fewer features considered per split\n",
    "    'n_jobs': -1,            # Still use all cores\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# === Memory-efficient raster loading ===\n",
    "def read_raster(path):\n",
    "    \"\"\"Load raster with memory optimization\"\"\"\n",
    "    with rasterio.open(path) as src:\n",
    "        # Read only the first band by default\n",
    "        data = src.read(1, masked=True)\n",
    "        profile = src.profile\n",
    "        print(f\"Loaded {os.path.basename(path)}: {data.shape}, {data.dtype}\")\n",
    "        return data.filled(0), profile\n",
    "\n",
    "# === Optimized patch extraction ===\n",
    "def extract_patches_efficient(*arrays, patch_size=PATCH_SIZE):\n",
    "    \"\"\"Memory-efficient patch extraction using sliding window\"\"\"\n",
    "    print(\"Extracting patches efficiently...\")\n",
    "    pad = patch_size // 2\n",
    "    \n",
    "    # Process features (all arrays except last)\n",
    "    features = []\n",
    "    for arr in arrays[:-1]:\n",
    "        # Use sliding window view (memory efficient)\n",
    "        window_shape = (patch_size, patch_size)\n",
    "        arr_patches = view_as_windows(arr, window_shape)\n",
    "        arr_patches = arr_patches.reshape(-1, patch_size*patch_size)\n",
    "        features.append(arr_patches)\n",
    "    \n",
    "    # Combine all features\n",
    "    features = np.concatenate(features, axis=1)\n",
    "    \n",
    "    # Get labels (center pixels)\n",
    "    labels = arrays[-1][pad:-pad, pad:-pad].flatten()\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# === Main Processing ===\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading rasters...\")\n",
    "    ld, profile = read_raster(os.path.join(\"E:/mtito_andei\", \"LD.tif\"))\n",
    "    d2f, _ = read_raster(os.path.join(\"E:/mtito_andei\", \"D2F.tif\"))\n",
    "    target, _ = read_raster(os.path.join(\"E:/mtito_andei\", \"Map.tif\"))\n",
    "\n",
    "    # Extract patches efficiently\n",
    "    features, labels = extract_patches_efficient(ld, d2f, target)\n",
    "    \n",
    "    # Filter data\n",
    "    valid_mask = (labels > 0)\n",
    "    features = features[valid_mask]\n",
    "    labels = labels[valid_mask]\n",
    "\n",
    "    # Filter rare classes\n",
    "    label_counts = pd.Series(labels).value_counts()\n",
    "    valid_classes = label_counts[label_counts >= MIN_SAMPLES_PER_CLASS].index\n",
    "    class_mask = np.isin(labels, valid_classes)\n",
    "    features = features[class_mask]\n",
    "    labels = labels[class_mask]\n",
    "\n",
    "    print(f\"\\nClass distribution:\\n{label_counts}\")\n",
    "\n",
    "    # Normalize features (memory-efficient StandardScaler)\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    joblib.dump(scaler, os.path.join(OUTPUT_DIR, \"scaler.joblib\"))\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=labels\n",
    "    )\n",
    "\n",
    "    # Train memory-optimized Random Forest\n",
    "    print(\"\\nTraining memory-efficient Random Forest...\")\n",
    "    rf = RandomForestClassifier(**RF_PARAMS)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"memory_efficient_rf_model.joblib\")\n",
    "    joblib.dump(rf, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[f\"Class {c}\" for c in valid_classes]))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "    # Feature importance plot\n",
    "    importances = rf.feature_importances_\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sorted_idx = importances.argsort()[::-1]\n",
    "    plt.bar(range(X_train.shape[1]), importances[sorted_idx], align='center')\n",
    "    plt.xticks(range(X_train.shape[1]), sorted_idx, rotation=90)\n",
    "    plt.xlabel(\"Feature index\")\n",
    "    plt.ylabel(\"Feature importance\")\n",
    "    plt.title(\"Feature Importance Ranking\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"feature_importance.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Full prediction with chunk processing\n",
    "    print(\"\\nGenerating full prediction map (chunked processing)...\")\n",
    "    chunk_size = 50000  # Process in chunks to save memory\n",
    "    all_preds = np.zeros(len(features), dtype=np.uint8)\n",
    "    \n",
    "    for i in tqdm(range(0, len(features), chunk_size), desc=\"Predicting\"):\n",
    "        chunk = features[i:i + chunk_size]\n",
    "        all_preds[i:i + chunk_size] = rf.predict(chunk)\n",
    "\n",
    "    # Create prediction map\n",
    "    predicted_map = np.zeros_like(target, dtype=np.uint8)\n",
    "    pad = PATCH_SIZE // 2\n",
    "    valid_pixels = (target[pad:-pad, pad:-pad] > 0) & (np.isin(target[pad:-pad, pad:-pad], valid_classes))\n",
    "    predicted_map[pad:-pad, pad:-pad][valid_pixels] = all_preds\n",
    "\n",
    "    # Apply median filter to reduce noise\n",
    "    predicted_map = median_filter(predicted_map, size=3)\n",
    "\n",
    "    # Save prediction\n",
    "    pred_profile = profile.copy()\n",
    "    pred_profile.update(dtype=rasterio.uint8, count=1, nodata=0)\n",
    "\n",
    "    with rasterio.open(os.path.join(OUTPUT_DIR, \"Predicted_Map.tif\"), 'w', **pred_profile) as dst:\n",
    "        dst.write(predicted_map, 1)\n",
    "\n",
    "    print(\"\\n=== Process Complete ===\")\n",
    "    print(f\"✅ All outputs saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "    # === LEARNING CURVE ===\n",
    "    print(\"\\nGenerating learning curve...\")\n",
    "\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    import seaborn as sns\n",
    "\n",
    "    train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "    train_sizes_abs, train_scores, test_scores = learning_curve(\n",
    "        estimator=rf,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        train_sizes=train_sizes,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=1,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    sns.lineplot(x=train_sizes_abs, y=train_scores_mean, label=\"Training Accuracy\", marker='o')\n",
    "    sns.lineplot(x=train_sizes_abs, y=test_scores_mean, label=\"Validation Accuracy\", marker='o')\n",
    "\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Number of Training Samples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"learning_curve.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Learning curve saved.\")\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7391c57-696a-4393-99fd-883daa2aa369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
